#!/bin/sh
#SBATCH --job-name=gpunep
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=4
#SBATCH --gres=gpu:4
#SBATCH --gpus-per-task=1
#SBATCH --partition=3080ti
echo "SLURM_SUBMIT_DIR is $SLURM_SUBMIT_DIR"

echo "Starting job $SLURM_JOB_ID at " `date`

echo "Running on nodes: $SLURM_NODELIST"

start=$(date +%s)
source /data/home/wuxingxing/anaconda3/etc/profile.d/conda.sh
conda activate torch2_feat

export PYTHONPATH=/data/home/wuxingxing/codespace/PWMLFF_nep/src:$PYTHONPATH
export PATH=/data/home/wuxingxing/codespace/PWMLFF_nep/src/bin:$PATH

module load cuda/11.8-share
module load intel/2020

#PWMLFF train train.json
#PWMLFF script nep_model.ckpt

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$(python3 -c "import torch; print(torch.__path__[0])")/lib:$(dirname $(dirname $(which python3)))/lib:$(dirname $(dirname $(which PWMLFF)))/op/build/lib

export PATH=/data/home/wuxingxing/codespace/lammps_setatom/src:$PATH

export LD_LIBRARY_PATH=/data/home/wuxingxing/codespace/lammps_setatom/src/PWMLFF/NEP_GPU:$LD_LIBRARY_PATH

mpirun -np 4  lmp_mpi_gpu -in in.lammps

end=$(date +%s)
take=$(( end - start ))


